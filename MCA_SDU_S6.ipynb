{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MCA_SDU_S6.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/htapiagroup/sistdist/blob/master/MCA_SDU_S6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njn20fpYCb4N",
        "colab_type": "text"
      },
      "source": [
        "# Sistemas Distribuidos y Ubicuos II\n",
        "## MCA Tercer cuatrimestre\n",
        "### Horacio Tapia-McClung\n",
        "\n",
        "## Resumen Semana 5\n",
        "\n",
        "* arreglos multidimensionales con `numpy` y `dask`\n",
        "* DataFrames con `pandas` y `dask`\n",
        "\n",
        "* leyendo multiples archivos de texto (.csv)\n",
        "* construyendo flujos retrasados\n",
        "* cronometraje de operaciones con dataframes, `pandas` vs. `dask`\n",
        "\n",
        "Cuando usar `pandas` y cuando usar `dask`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYRZw6axDvq0",
        "colab_type": "text"
      },
      "source": [
        "# Analizando los viajes en taxi de la Ciudad de NY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOQEt6EpCaUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download taxi data\n",
        "\n",
        "import os\n",
        "plantilla = 'yellow_tripdata_2018-{:02d}.csv'\n",
        "plantillaURL = 'wget https://s3.amazonaws.com/nyc-tlc/trip+data/'+plantilla\n",
        "urls = (plantillaURL.format(k) for k in range(1,13)) # generator\n",
        "for url in urls:\n",
        "  os.system(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKbpWxogEk_B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "05e76d53-a37c-4eb7-d575-3a59d52ed7c1"
      },
      "source": [
        "ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/                 yellow_tripdata_2018-07.csv\n",
            "yellow_tripdata_2018-01.csv  yellow_tripdata_2018-08.csv\n",
            "yellow_tripdata_2018-02.csv  yellow_tripdata_2018-09.csv\n",
            "yellow_tripdata_2018-03.csv  yellow_tripdata_2018-10.csv\n",
            "yellow_tripdata_2018-04.csv  yellow_tripdata_2018-11.csv\n",
            "yellow_tripdata_2018-05.csv  yellow_tripdata_2018-12.csv\n",
            "yellow_tripdata_2018-06.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCrOpC8DGVfJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "d43a8f85-70c7-481b-f388-315771cfe5af"
      },
      "source": [
        "%ll -h yellow_tripdata_2018-*.csv"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root 737M Aug  3  2018 yellow_tripdata_2018-01.csv\n",
            "-rw-r--r-- 1 root 715M Aug  3  2018 yellow_tripdata_2018-02.csv\n",
            "-rw-r--r-- 1 root 794M Aug  3  2018 yellow_tripdata_2018-03.csv\n",
            "-rw-r--r-- 1 root 784M Aug  3  2018 yellow_tripdata_2018-04.csv\n",
            "-rw-r--r-- 1 root 777M Aug  3  2018 yellow_tripdata_2018-05.csv\n",
            "-rw-r--r-- 1 root 734M Aug  3  2018 yellow_tripdata_2018-06.csv\n",
            "-rw-r--r-- 1 root 661M Feb  5 15:07 yellow_tripdata_2018-07.csv\n",
            "-rw-r--r-- 1 root 661M Feb  5 15:09 yellow_tripdata_2018-08.csv\n",
            "-rw-r--r-- 1 root 678M Feb  5 15:12 yellow_tripdata_2018-09.csv\n",
            "-rw-r--r-- 1 root 744M Feb  5 15:14 yellow_tripdata_2018-10.csv\n",
            "-rw-r--r-- 1 root 687M Feb  5 15:16 yellow_tripdata_2018-11.csv\n",
            "-rw-r--r-- 1 root 689M Feb  5 15:19 yellow_tripdata_2018-12.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajL98MT0Ga5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW3y34G7GouT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4526c7cd-987a-4973-a507-b10c98975bae"
      },
      "source": [
        "df = pd.read_csv('yellow_tripdata_2018-01.csv')\n",
        "df.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8759874, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxkoZIPLGuPy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "42f4065d-a873-4b56-ae8d-138fe003fe04"
      },
      "source": [
        "\n",
        "df.columns"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
              "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
              "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
              "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
              "       'total_amount'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuOcKUyLGujA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "14ec25a4-1c02-4e30-d870-5f3028163da5"
      },
      "source": [
        "df['payment_type'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    6105871\n",
              "2    2598947\n",
              "3      43204\n",
              "4      11852\n",
              "Name: payment_type, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBuV0RXYG6Ze",
        "colab_type": "text"
      },
      "source": [
        "Using `dask`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG61SpwvHCNS",
        "colab_type": "text"
      },
      "source": [
        "## Reading & cleaning files\n",
        "\n",
        "Here you'll be working with a subset of the NYC Taxi Trip data. The first step is to use the Dask dd.read_csv() function to read multiple files at once. Dask will automatically concatenate the contents of the files into a single DataFrame. Notice that you'll use the option assume_missing=True in the call to dd.read_csv() to suppress warning messages.\n",
        "\n",
        "Your job is to use a glob pattern containing the * character to read all of the CSV files from the taxi/ subdirectory into a single Dask DataFrame. You'll then construct a new column called 'tip_fraction' using the 'tip_amount' and 'total_amount' columns. The 'total_amount' is the sum of the fare, other fees, and the tip_amount.\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "\n",
        " * Read all .csv files from the taxi/ directory (with a wildcard pattern *).\n",
        " * Create a column 'tip_fraction', which is the result of the 'tip_amount' divided by the difference of the 'total_amount' and 'tip_amount' columns.\n",
        " * Convert the 'tpep_dropoff_datetime' column to datetime using dd.to_datetime().\n",
        " * Create a column 'hour' using the .dt.hour attribute of the 'tpep_dropoff_datetime' column.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRM8Y8c4G00D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dask.dataframe as dd\n",
        "# Read all .csv files: df\n",
        "df = dd.read_csv('taxi/yellow*.csv', assume_missing=True)\n",
        "\n",
        "# Make column 'tip_fraction'\n",
        "df['tip_fraction'] = df['tip_amount'] / (df['total_amount'] - df['tip_amount'])\n",
        "\n",
        "# Convert 'tpep_dropoff_datetime' column to datetime objects\n",
        "df['tpep_dropoff_datetime'] = dd.to_datetime(df['tpep_dropoff_datetime'])\n",
        "\n",
        "# Construct column 'hour'\n",
        "df['hour'] = df['tpep_dropoff_datetime'].dt.hour"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v3rGj49HRXT",
        "colab_type": "text"
      },
      "source": [
        "## Filtering & grouping data\n",
        "\n",
        "You have the Dask dataframe df prepared using multiple CSV files from the last exercise. It contains a subset of the 2015 yellow taxi ride data from New York City with some additional columns from preprocessing. Remember, none of the files have actually been loaded, nor has any computation been done to construct the new columns.\n",
        "\n",
        "Your task now is to build a pipeline of computations to compute the hourly average tip fraction for each hour of the day across the entire year of data. You'll have to filter for payments of type 1 (credit card transactions) from the 'payment_type' column, group transactions using the 'hour' column, and finally aggregate the mean from the 'tip_fraction' column.\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "* Filter out rows where payment_type is 1 and call the resulting dataframe credit.\n",
        "* Group credit using the 'hour' column and call the result 'hourly'.\n",
        "* Select the 'tip_fraction' column and aggregate the mean.\n",
        "* Display the data type of result.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMTV-v4pHR8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Filter rows where payment_type == 1: credit\n",
        "credit = df[df.payment_type==1]\n",
        "\n",
        "# Group by 'hour' column: hourly\n",
        "hourly = credit.groupby('hour')\n",
        "\n",
        "# Aggregate mean 'tip_fraction' and print its data type\n",
        "result = hourly['tip_fraction'].mean()\n",
        "print(type(result))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxeF1C4dHek7",
        "colab_type": "text"
      },
      "source": [
        "## Computing & plotting\n",
        "\n",
        "Now that you've got the entire delayed pipeline prepared it's time compute and plot the result. Matplotlib has been imported for you as plt.\n",
        "\n",
        "Warning: The execution of of this exercise is expected to be several seconds.\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "\n",
        "* Perform the computation on result and assign it to tip_frac.\n",
        "* Print the type of tip_frac.\n",
        "* Hit 'Submit Answer to view the plot.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjcHymAbHnk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Perform the computation\n",
        "tip_frac = result.compute()\n",
        "\n",
        "# Print the type of tip_frac\n",
        "print(type(tip_frac))\n",
        "\n",
        "# Generate a line plot using .plot.line()\n",
        "tip_frac.plot.line()\n",
        "plt.ylabel('Tip fraction')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}